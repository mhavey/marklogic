# Human Resources Example

## Intro

This example shows the following:
- How to model in UML human resources (employee, department) entities. 
- How to map the UML model to a MarkLogic Entity Services model.
- How to setup a MarkLogic Data Hub to house the human resources data. 
- How to ingest source data into the Data Hub staging database. 
- How to harmonize this source data into the Data Hub final database. Significantly, this harmonized data conforms to the UML model. The harmonization code is generted by the toolkit's *cookie cutter*. 
- How to link departments and employees using semantics. The model specifies the semantic relationships. The code to create triples is GENERATED when we transform the UML model to Entity Services!!

Here is a blog post about this example: <http://developer.marklogic.com/blog/uml-modeling-marklogic-entity-services-semantics>.

For more on MarkLogic's Data Hub Framework (aka DHF), visit its GitHub page: <https://github.com/marklogic-community/marklogic-data-hub>. 

This example requires DHF 4.1 or higher. If you have an earlier version of DHF and want to run this example, use the UNO release of the UML toolkit at <https://github.com/mhavey/marklogic/releases/tag/0.0.2>. 

Our source data comes from one of the DHF examples. <https://github.com/marklogic-community/marklogic-data-hub/tree/master/examples/hr-hub>

We use the following ontology: <https://www.w3.org/TR/vocab-org/>

## Model
Here is the our UML model:

![DHFEmployeeSample](../umlModels/DHFEmployeeSample.png)

## How We Use Data Hub

A few points about our use of DHF.

First, here is the purpose of the six main databases that constitute DHF:
- Staging: This holds source data:
  - Employee data from ACME Tech
  - Employee data from Global Corp
  - Employee salary data from Global Corp
  - Department data from Global Corp
- Final
  - Harmonized employee documents that conform to the model
  - Harmonized department documents that conform to the model
  - Semantic triples representing: employee reporting structure; employee department membership; acquisition relationship between Global and ACME.
- Modules: This holds server-side modules:
  - The XMI2ES transform and code generator (aka *cookie cutter*). As a transform it translates your UML model to Entity Services. As a code generator, it generates server-side code to harmonize your data according to the model. 
  - The generated DHF harmonization modules.
  - DHF internal modules
- Schemas for Staging: This holds TDE templates and other schematic artifacts for staging. This example does not use schemas.
- Schemas for Final: This holds TDE templates and other schematic artifacts for final. This example does not use schemas.
- Jobs: This database, maintained by DHF, tracks the execution of DHF jobs. These jobs include the HR harmonization flows.

Now, about where the model fits:
- It is the data in FINAL db that conforms to the model.
- Staging DB does not conform to the model.
- Harmonization takes staging data and fashions it into the form expected by the model. Our toolkit is able to generate the harmonization code based on its knowledge of the model.  

Finally, semantics: We keep relationships "soft". Don't link documents to each other via key. Rather, use the following semantic triples:

- An employee reportsTo another employee
- An employee is a memberOf a department
- Global's acquisition of ACME uses an organizational change event.

In the UML model, we use stereotypes to describe the semantic relationships. The transform model, which converts our UML model to Entity Services, generates XQuery code to create triples based on these semantic relationships. In building our harmonization logic, we use this generated code.

## The Cooking Show Approach

Like a cooking show, this example describes how to prepare the souffle but also shows a souffle already prepred for you to consume. 

The "prepared" souffle includes:
- The UML model.
- An ML-gradle project for DHF with tasks added. 
- MLCP gradle tasks to ingest the data to STAGING
- Harmonization plugins to harmonize the data to FINAL. These plugins are generated by the toolkit (*stamped out by the cookie cutter*) but are then tweaked to deal with the fine details. The tweaks are included in the prepared souffle!

If you were to start from scratch, you would follow this recipe:
- Devise the UML model in your favorite UML editor. 
- Create a data hub gradle project and embellish it with tasks to load source data via MLCP
- Further embellish the gradle project with tasks to load your UML model, transform it to Entity Services, and generate harmonization code from it. 
- Tweak the generated harmonization code

## How to run:

Our project uses gradle. Before running, view the settings in gradle.properties. Create a file called gradle-local.properties and in this file override any of the properties from gradle.properties. 

### Install the Hub

We will start simple, setting up the basic hub. Run the following:

gradle -PenvironmentName=local -i mlDeploy

Confirm:
- No errors in gradle output
- The following app servers were created:
  * xmi2es-examples-hr-FINAL
  * xmi2es-examples-hr-STAGING
  * xmi2es-examples-hr-JOBS
- The following databases were created:
  * xmi2es-examples-hr-FINAL
  * xmi2es-examples-hr-STAGING
  * xmi2es-examples-hr-MODULES
  * xmi2es-examples-hr-final-SCHEMAS
  * xmi2es-examples-hr-final-TRIGGERS
  * xmi2es-examples-hr-staging-SCHEMAS
  * xmi2es-examples-hr-staging-TRIGGERS

### Include the Toolkit
Next we include in the hub our toolkit's transform and cookie cutter. 

Run the following:

gradle -PenvironmentName=local -i includeXMI2ESTransform mlReloadModules

Confirm:
- Modules DB (xmi2es-examples-hr-MODULES) contains the following module:
  * /xmi2es/xmi2esTransform.xqy - Main module of the toolkit's transform

### Load and Transform the HR UML Model

Next, move our UML model into ML as an ES model. Run the following:

gradle -PenvironmentName=local -i ingestModel deployESModelToFinal loadExtendedModel

Confirm:
- Final DB (xmi2es-examples-hr-FINAL) includes the following documents
  * /marklogic.com/entity-services/models/DHFEmployeeSample.json (The deployed ES model)
  * /xmi2es/es/DHFEmployeeSample.json (The ES model descriptor converted to JSON form)
  * /xmi2es/extension/DHFEmployeeSample.ttl (Semantic triples that extend our model)
  * /xmi2es/extension/DHFEmployeeSample.txt (A text summary of our model extension)
  * /xmi2es/gen/DHFEmployeeSample/lib.xqy (Initial generated code from the model. This is a *precursor* to the cookie-cut harmonization. That will come later.)
  * /xmi2es/findings/DHFEmployeeSample.xml (Problems found during transformation)
  * /xmi2es/xmi/DHFEmployeeSample.xml (The original UML model as an XMI document)
- Check /xmi2es/findings/DHFEmployeeSample.xml for issues during transform. It should not indicate any issues.
- In Query Console, open a tab of type SPARQL, point to the final DB, run the following query, and verify you get any results. This means the ES model is in FINAL and its semantic metadata is populated.

select * where {?s ?o ?p}

Among the results, you should see the following:
- <http://com.marklogic.es.uml.hr/HR-0.0.1/Employee> <http://marklogic.com/entity-services#property> http://com.marklogic.es.uml.hr/HR-0.0.1/Employee/emails> from basic ES model
- <http://com.marklogic.es.uml.hr/HR-0.0.1/Employee/memberOf> <http://marklogic.com/xmi2es/xes#relationship>  "association" from the extended ES model

### Run Cookie-Cutter to Create DHF Entities and Flows for HR Model

gradle -PenvironmentName=local -i umlCreateEntities -Pmodel=DHFEmployeeSample -PentitySelect=infer -PpluginFormat=xqy -PdataFormat=xml

Confirm:
- In your local gradle project you now have a folder called data/cookieCutter-dump. This contains generated DHF plugins and harmonization flows for the Employee and Department classes.
- In your gradle plugins folder, the plugins from cookieCutter-dump have been copied. If you run an mlReloadModules, gradle will deploy these plugins to the hub modules database.
- In the final database xmi2es-examples-hr-FINAL), the code from cookieCutter-dump exists as text documents in the collections cookieCutter and DHFEmployeeSample.

### Create Input Flows For Source Data

For your newly created Employee and Department entities you need input flows for ingestion of source data. Run the following standard DHF gradle commands to create these flows.

gradle -PenvironmentName=local -i hubCreateInputFlow -PentityName=Employee -PflowName=LoadEmployee -PdataFormat=xml -PpluginFormat=xqy

gradle -PenvironmentName=local -i hubCreateInputFlow -PentityName=Department -PflowName=LoadDepartment -PdataFormat=xml -PpluginFormat=xqy


### Ingest

TODO: pre-req: input flow exists, duh
Ingest staging data and some triples for FINAL	

Run the following:

gradle -PenvironmentName=local -i loadSummaryOrgTriples runInputMLCP

Confirm:
- In STAGING (xmi2es-examples-hr-STAGING) we now have 2008 documents. Of these:
  * 1002 are in Employees collection
  * 1000 are in Salary collection
  * 5 are in Department collection

- In FINAL (xmi2es-examples-hr-FINAL) we have the a document containing triples in the collection http://www.w3.org/ns/org.

.... THE REST IS UNDER CONSTRUCTION ...

### Harmonize
Run harmonization to move employee and department data to FINAL.

Run the following:

gradle -PenvironmentName=local -i hubRunFlow -PentityName=Department -PflowName=HarmonizeDepartment

gradle -PenvironmentName=local -i hubRunFlow -PentityName=Employee -PflowName=HarmonizeEmployee

Confirm:
FINAL now contains:  
  - 5 documents in Department collection
  - 1002 documents in Employee collection

## Explore the Data
In Query Console, import the workspace XMI2ESHR.xml. In each tab, try the query to explore an aspect of the data.
